%TODO
% spell check, b.v. ispell op de uva
% zoeken op TODO punten

%% vi: set tabs top=2, set textwidth=80
\documentclass[a4paper,11pt]{article}

\usepackage{homework}
% \usepackage{graphicx, subfigure}
% \usepackage{verbatim}
% \usepackage{algorithm, algorithmic}
% \usepackage{amsmath, amsthm, amssymb}
\usepackage[english]{babel}

\title{Mean shift object tracking\\ Lab report for IMS}

\date{December 22, 2009}

\begin{document}
\maketitle
\section{Introduction}
	Videos are ubiquitous; in the UK it has been claimed that there is one observation camera per 14 citizens [cite{yadyada} CLAIM: "A CCTV camera for every 14 citizens."
	David Davis, resignation statement, 12 June 2008 ]. YouTube.com the largest video website in the USA with a marketshare of 99\% of all watched online videos serves more than 10 Billion movies a month \footnote{http://mashable.com/2009/09/28/august-comscore-data/}
	Furthermore, the amount of videos uploaded to the site through mobile phones is growing exponentially \footnote{http://arstechnica.com/apple/news/2009/06/mobile-uploads-to-youtube-up-400-after-iphone-3gs-launch.ars}. 
	This plethora of video content makes automated video analysis desirable. Ideally we would like to analyse videos to be able to extract their content, for instance, in order to make them accessible for search or to alert the viewer of important developments. One of these analyses is tracking an object through multiple frames of video.

	Generally, tracking can be done in two distinct manners; First, a model of the object to be tracked is built. One can think of a wireframe model of the object together with texture or color information. 
	In every frame this model is searched for, and the location that resembles the model best is the location of the relevant object. A problem with this approach is that a model for every object needs to be built.. Becuase of this tedious task, this approach can only be applied to small specialized domains. 
	The other approach does not build a full model, but it looks at the appearance of an object and searches for regions that appear the same. This is thus not a fully descriptive model; rather it is an appearance based model. 
	The underlying assumption behind this way of tracking is that small local features of the tracked object appear the same over multiple frames. For instance, one such feature is color.

	This paper will present and compare methods within the appearance based tracking paradigm; namely the color based mean-shift tracker and brute-force tracker. 
	Since color is the feature that will be tracked, different color models will be presented and applied. Following this, subsequent tracking results on different videos for both trackers will be discussed.
	Specifically, we want to focus on the mean-shift tracker and explain through experiments how the tracker behaves under varying video conditions (such as occlusion and objects of varying scales), and what the influence of the used color model is.
	As said at the beginning of this section, videos are pervasive, and their analysis should therefore ideally be done in realtime. The speed of the tracker will, therefore, also be discussed.

	This paper is organised as follows:  after the introduction of the topic in section 1, the theory behind the used trackers and colorspaces will be discussed in section 2.
	Section 3 will be devoted to the implementation of the presented theories. The experimental setup, a description of the data, subsequent results and their discussion will be presented in section 4. 
	Finally, section 5 will present the main conclusions on color based mean shift tracking.

\section{Theory}	
	This section will explain the main theories used in developing the mean shift tracker. 
	\subsection{Colorspaces}
		It was previewed in the introduction that an object would be tracked by its appearance, and that the feature used to do so would be color. In this section we will describe three different color models and their relevance to appearance based tracking, but first we will discuss some general properties of color.

The color a camera detects is dependent on the Spectral Power Distribution(SPD) of the light source, the reflectance factor of a patch of the object, the color matching functions of the camera sensors and the geometric arrangement of the lightsource(s), object and observer. The SPD describes for the whole visible light spectrum with what intensity every wavelength is being radiated. The reflectance factor  describes how much each part of the spectrum gets reflected and how much gets absorbed. The color matching functions indicate the magnitude of the response of a camera sensor for every wavelength of incoming radiation. Last, the geometric arrangement also influences the color.

Here it is important to distinguish between the reflectance factor of a patch of an object, and the appearance of this patch's color to a camera. All factors described above influence the appearance of the patch, however the reflectance factor stays constant. Therefore, we want to track an object based on its reflectance factor since this is the only factor intrinsic to the object.  Hence, we want to have a color model which is ideally invariant to all factors that influence the appearance of the object except for the reflectance factor.  

		\subsubsection{RGB}
		
		All percievable colors can, based on trichromacy theory [CLAIM quote gevers], be modeled by the response of three sensors. 
		
		RGB is a standard colorspace used in computer vision, which desribes the detected colors as a tri-stimulus, (R,G,B). Where R corresponds the response of the Red sensor, which is most sensitive to Red, G to the response of the green sensor and B to the resonse of the Blue sensor.

		% TODO where should invariants go?, say some general about invariants and show table[Color Feature Detection, Geveres]
		However, this model has some problems for the domain of object tracking. it is not invariant to illumination intensity, which means that if the amount of light that falls on an object changes, th appearance changes, the human analog is the perception of shades. 
		Furthermore, RGB 
		

		

		\subsubsection{Normalised RGB}
		normalised RGB is a colormodel which is invariant to illumination intensity, orientation of the object surface and also viewpoint invariant. 
		The normalised RGB colorspace is 3-dimensional but since all 3 channels are divided by the intencity we have, r+g+b =1,, therefore it is overdetermined as a 3-dimensional system and can be described in 2 dimensions r,g, where b can be deduced through 1-(r+g).
		normalised RGB is derived from RGB by deviding the reponse of each color channel by the intensity, thus creating an intensity invariant colorspace
		\subsubsection{Hue}
		The Hue is derived from a different color space, where a color is not described as the response of three RGB sensors but it is described as a Hue, which can be seen as a pure spectral color, saturation which describes how pure the color is, if it is fully satureated there is a pure spectral color, less saturated colors have more white mixed in. Last the intensity describes how bright the color is. 
		The colorspace consisting of only Hue is 1-dimensional.
		Hue is invariant to illumination and object and observer geometry and highlights. [quote invariant claim]
	\subsection{Histogram}
		We want to describe an image patch as a probability density function(pdf). This means that we could compare different image patches and a measure of similarity would be how much both distributions look alike %TODO uglysentence thatis
		Furthermore we could compare patches of different size since the probability distribution would describe to what relative frequency colors are in a patch.
		Ideally the PDF  would take every color and describe its relative frequency.However this would lead to a pdf which is too sparse. Therefor we collect similar colors in bins and compare the relative frequencies of this more coarse color description. A problem with this is that too few bins would lead to a pdf which is too coarse. Therefore finetuning the number of bins is a delicate task, of balancing between representations which are too coarse and too sparse, to be useful. 

	\subsection{Brute force}
		First the tracked object is modeled by computing a color histogram, the
		target model.
		In the next frame a new color histogram is computed on every location,
		these are the candidate models.
		The target model is compared with all candidate models using a distance
		measure. The new location is determined by the location of the candidate
		histogram with the lowest distance.
		
		\paragraph{Semi Brute force}
		Using the fact that we work with 25 frames every second and objects are moving
		within a maximum speed, an assumption can be made that the object
		location should be close to the previous location. This optimalization
		ignores a lot of unnecessary computations.

	
	\subsection{Meanshift}
		Mean shift is an algorithm that finds the most probable target position of a
		tracked object in a frame.

		First a the tracked object is modeled by computing a color histogram.
		Likewise on the same location but in the next frame an other color histogram is
		computed.

		These two histograms are compared using a Bhattagarya distance measure. This
		results in a weight image where high values represent pixels that are
		simmilar.  For the intuition, when an object moved to the left, the weight
		values will be high on the left side. Furthermore the weights will be low on
		the right side because new information (different colors) entered the
		searchwindow. 

		This is used to weight an image which contain relative locations
		(where the origin is situated in the center of this image). This result in
		an image where each pixel represents a weighted shift. It is easy to see
		that the mean shift is the mean of this image.
	
	% TODO 
	%Above steps are done iteratively till a 

	% (2) is to be sure pixels that are farther away from the center are assigned a lower weight.

	% To prevent overshoot the mean shift vector is divided by 2 and added up to
	% the old location Y1.

	% The algorithm repeats on this new location until the mean shift vector is
	% smaller then a certain convergence threshold, for example 1 pixel.

\section{Implementation}

\section{Results} 
	\subsection{Experimental setup} 
	binsize is per colorchannel
	\subsection{Brute force} 
	\subsection{Meanshift} 

	\begin{tabular}{l | l | l | l}
		scene	& 	colorspace	& downsampled & keeped track with binsize & 4 & 8 & 16 & 32\\
		\hline
		soccer 	& 	RGB	 		& 1x		  &							  & + & + & +  &  -\\
		soccer 	& 	RGB	 		& 1x		  &							  & + & + & +  &  -\\
		soccer 	& 	rg	 		& 1x 		  &							  & + & + & +  &  -\\
		soccer 	& 	H	 		& 1x		  &							  & + & + & +  &  -\\
		soccer 	& 	HS	 		& 1x		  &							  & + & + & +  &  -\\
		soccer 	& 	HSV	 		& 1x		  &							  & + & + & +  &  -\\
		soccer 	& 	RGB	 		& 2x		  &							  & - & - & -  &  -\\
		soccer 	& 	rg	 		& 2x 		  &							  & - & + & -  &  -\\
		soccer 	& 	H	 		& 2x		  &							  & - & + & -  &  -\\
		soccer 	& 	HS	 		& 2x		  &							  & - & + & -  &  -\\
		soccer 	& 	HSV	 		& 2x		  &							  & - & - & -  &  -\\
	\end{tabular}	

	conclusions

	%TODO compare with other scene
	%make the comparison automatic, use wrapper function and write figure
	%windows to file with binsize etc. as filename
\subsection{Discussion} % discussion of results
		performs bad on low binsize (obvious) and downsampled images (obvious)\\

		performs bad on a very high (32) a binsize even with not downsampled
		images, the high bin size causes to lose generalisation power (same object other pose)\\
		
		colorspace RGB and HSV only keeped track with a non downsampled image,
		that is probably because it uses intensity i


\section{Conclusions} \label{sec:conc}
\section{Future Work} \label{sec:fut}
Observe how you can improve your design and them describe how you implemented this change or, for lack of time, describe how you would change your design. 

e.g. a different color space or the number of bins in the histogram
test the tracker also on a video of a domain other than soccer (or any other sport on a green field)

% variable tracking window size 

%TODO write something about kalman

%TODO would be better to have a ground truth and compair the tracking
%coordinates to the ground truth, no just a binary val (keeped track or not) is
%used


\section{References} 

% \begin{figure}[!ht]
% \centering
% \includegraphics[height=7cm]{img/fprate}
% \caption{The false positive rate per layer, averaged over the test set.}
% \label{fig:fprate}
% \end{figure}

% \renewcommand\bibname{References}
% \bibliography{references}
% \bibliographystyle{IEEEtran}
\end{document}
